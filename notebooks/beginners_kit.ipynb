{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAIRE Beginners Kit\n",
    "\n",
    "The **OpenAIRE Graph** is an Open Access dataset containing metadata about research products (literature, datasets, software, and other research products) linked to other entities of the research ecosystem, such as organisations, grants, and data sources.\n",
    "\n",
    "The large size of the OpenAIRE Graph is a major impediment for beginners to familiarise with the underlying data model and explore its contents. Working with the Graph in its full size typically requires access to a huge distributed computing infrastructure which cannot be easily accessible to everyone.\n",
    "\n",
    "The OpenAIRE Beginnerâ€™s Kit aims to address this issue. It consists of two components: a subset of the Graph composed of the research products published between `2024-06-01` and `2024-12-31`, all the entities connected to them and the respective relationships, and the present Jupyter notebook that demonstrates how you can use `PySpark` to analyse the Graph and get answers to some interesting research questions.\n",
    "\n",
    "This notebook is structured in sections to help you navigate the different cells; you can visualise the structure by clicking on the third icon in the leftmost menu.\n",
    "\n",
    "You can run each cell individually (`shift+enter`with a cell highlighted) or run everything at once from the top menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlsplit\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "zenodo_url = \"https://zenodo.org/record/14891799/files/\"\n",
    "\n",
    "openaire_files = [zenodo_url + \"communities_infrastructures.tar\",\n",
    "                  zenodo_url + \"dataset.tar\",\n",
    "                  zenodo_url + \"datasource.tar\",\n",
    "                  zenodo_url + \"organization.tar\",\n",
    "                  zenodo_url + \"otherresearchproduct.tar\",\n",
    "                  zenodo_url + \"project.tar\",\n",
    "                  zenodo_url + \"publication.tar\",\n",
    "                  zenodo_url + \"relation.tar\",\n",
    "                  zenodo_url + \"software.tar\"]\n",
    "\n",
    "\n",
    "\n",
    "def download_and_extract(url, path):\n",
    "    tar_name = urlsplit(url).path.split('/')[-1] # publication.tar\n",
    "    tar_path = os.path.join(path, tar_name) # data/raw/publication.tar\n",
    "    untarred_folder = tar_name.split('.')[0] # publication\n",
    "    untarred_path = os.path.join(path, untarred_folder) # data/raw/publication\n",
    "    if not os.path.exists(untarred_path):\n",
    "        if not os.path.exists(tar_path):\n",
    "            print(f\"downloading ${url}\")\n",
    "            try:\n",
    "                with requests.get(url, stream=True) as response:\n",
    "                    response.raise_for_status()\n",
    "                    with open(tar_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(\"Error downloading the file:\", e)\n",
    "\n",
    "        print(f\"untar ${tar_name}\")\n",
    "        with tarfile.open(tar_path, \"r\") as tar:\n",
    "            tar.extractall(path)\n",
    "\n",
    "        print('cleaning')\n",
    "        os.remove(tar_path)\n",
    "\n",
    "\n",
    "# Download data into /data/raw\n",
    "for tar in openaire_files:\n",
    "    download_and_extract(tar, \"/app/openaire/data/raw\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.display import JSON as pretty_print\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data subset is organised in part files under the `data/raw` folder. \n",
    "\n",
    "If you try to load the data straight into memory, one part file would fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('data/raw/publication/part*'))\n",
    "df = pd.read_json(files[0], compression='gzip', lines=True)\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you try to load the whole thing, even just the publications, the chances are slim.\n",
    "\n",
    "If you try uncommenting and running the following lines, after some time, the kernel will die while trying and restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = sorted(glob.glob('data/raw/publication/part*'))\n",
    "# publications_df = pd.concat(pd.read_json(f, compression='gzip', lines=True) for f in files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's see how `Spark` can help us.\n",
    "\n",
    "First thing first, let's create the Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the datasets about OpenAIRE entitities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "inputPath = 'data/raw/'\n",
    " \n",
    "publications = spark.read.json(inputPath + 'publication')\n",
    "datasets = spark.read.json(inputPath + 'dataset')\n",
    "software = spark.read.json(inputPath + 'software')\n",
    "others = spark.read.json(inputPath + 'otherresearchproduct')\n",
    "datasources = spark.read.json(inputPath + 'datasource')\n",
    "organizations = spark.read.json(inputPath + 'organization')\n",
    "projects = spark.read.json(inputPath + 'project')\n",
    "communities = spark.read.json(inputPath + 'communities_infrastructures')\n",
    "relations = spark.read.json(inputPath + 'relation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some `Temporary views`, which is similar to a real SQL table that you can query via Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications.createOrReplaceTempView(\"publications\")\n",
    "datasets.createOrReplaceTempView(\"datasets\")\n",
    "software.createOrReplaceTempView(\"software\")\n",
    "others.createOrReplaceTempView(\"others\")\n",
    "datasources.createOrReplaceTempView(\"datasources\")\n",
    "organizations.createOrReplaceTempView(\"organizations\")\n",
    "projects.createOrReplaceTempView(\"projects\")\n",
    "communities.createOrReplaceTempView(\"communities\")\n",
    "relations.createOrReplaceTempView(\"relations\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's count the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of publications %s\"%publications.count())\n",
    "print(\"number of datasets %s\"%datasets.count())\n",
    "print(\"number of software %s\"%software.count())\n",
    "print(\"number of other research products %s\"%others.count())\n",
    "print(\"number of datasources %s\"%datasources.count())\n",
    "print(\"number of organizations %s\"%organizations.count())\n",
    "print(\"number of communities %s\"%communities.count())\n",
    "print(\"number of projects %s\"%projects.count())\n",
    "print(\"number of relations %s\"%relations.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, the same could be achieved in SQL via Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM publications\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise sample data structures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some data now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a generic publication (link to documentation: https://graph.openaire.eu/docs/data-model/entities/research-product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pretty_print(json.loads(publications.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generic dataset (link to documentation: https://graph.openaire.eu/docs/data-model/entities/research-product#data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(json.loads(datasets.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A software (https://graph.openaire.eu/docs/data-model/entities/research-product#software)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(json.loads(software.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An other research product (https://graph.openaire.eu/docs/data-model/entities/research-product#other-research-product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(json.loads(others.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a data source (link to documentation: https://graph.openaire.eu/docs/data-model/entities/data-source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pretty_print(json.loads(datasources.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An organization (link to documentation: https://graph.openaire.eu/docs/data-model/entities/organization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pretty_print(json.loads(organizations.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A project (link to documentation: https://graph.openaire.eu/docs/data-model/entities/project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pretty_print(json.loads(projects.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A community (link to documentation: https://graph.openaire.eu/docs/data-model/entities/community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pretty_print(json.loads(communities.toJSON().first()), expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "And finally, a relation (link to documentation: https://graph.openaire.eu/docs/data-model/relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pretty_print(json.loads(relations.toJSON().first()), expanded=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple queries "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the exercises follow the template below.\n",
    "```python\n",
    "query = \"\"\"\n",
    "SELECT <columns>\n",
    "FROM <table>\n",
    "[WHERE <conditions>]\n",
    "[GROUP BY <fields>]\n",
    "[ORDER BY <fields> DESC|ASC]\n",
    "[LIMIT <n_rows>]\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()\n",
    "```\n",
    "\n",
    "Your query is written as a string inside the `query` variable and then executed with `spark.sql(query)`. \n",
    "\n",
    "`toPandas()` results in the collection of all records in the PySpark DataFrame to the driver program and should be done only on a small subset of the data. Running queries that return a large number of rows could yield an out-of-memory exception and crash the application. If this is the case, it is always better to limit the number of rows with the `LIMIT` clause (see below).\n",
    "\n",
    "In case the kernel dies unexpectedly (e.g., a connection error shows up after executing a cell), it is necessary to restart it from the top menu. In this case, you will need to reload the data from the beginning **without downloading everything from Zenodo again**.\n",
    "\n",
    "The reference guide for Spark SQL can be found here: https://spark.apache.org/docs/latest/sql-ref.html.\n",
    "\n",
    "**Generative AI and LLMs**, such as ChatGPT or Gemini, work great to get familiar with Spark SQL syntax and built-in functions; just frame your question in an appropriate way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** find publications with a keyword in the title, e.g., `covid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this, we can use the standard SQL operator `LIKE`.\n",
    "\n",
    "On LLMs, for example, the prompt `In Spark SQL, write a query that checks if a column mainTitle contains the string covid` would produce the intended query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM publications\n",
    "WHERE mainTitle LIKE '%covid%'\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative, we could use a convenient built-in function that checks if a string contains another string.\n",
    "The documentation can be found here: https://spark.apache.org/docs/latest/api/sql/#contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM publications\n",
    "WHERE CONTAINS(mainTitle, 'covid')\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count publications per date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT publicationDate AS year, COUNT(*) AS n_pubs\n",
    "FROM publications\n",
    "GROUP BY year\n",
    "ORDER BY year DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count publications by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT language.code, COUNT(*) AS n_papers\n",
    "FROM publications\n",
    "GROUP BY language\n",
    "ORDER BY n_papers DESC\n",
    "LIMIT 25\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count publications by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT country.code AS code, COUNT(DISTINCT id) AS n_pubs\n",
    "FROM publications\n",
    "  LATERAL VIEW EXPLODE(countries) AS country\n",
    "GROUP BY code\n",
    "ORDER BY n_pubs DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the most occurring publication subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT term, COUNT(term) as occurrences\n",
    "FROM publications\n",
    "    LATERAL VIEW explode (subjects.subject.value) as term\n",
    "GROUP BY term\n",
    "ORDER BY occurrences DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** find active projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT id, title,\n",
    "    EXTRACT(YEAR FROM DATE(projects.startDate)) AS start_year,\n",
    "    EXTRACT(YEAR FROM DATE(projects.endDate)) AS end_year\n",
    "FROM projects\n",
    "WHERE EXTRACT(YEAR FROM DATE(projects.endDate)) > 2024\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count projects by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT subject, COUNT(id) AS n_projects\n",
    "FROM projects\n",
    "  LATERAL VIEW EXPLODE(subjects) AS subject\n",
    "GROUP BY subject\n",
    "ORDER BY n_projects DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count active projects by subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT subject, COUNT(id) AS n_projects\n",
    "FROM projects\n",
    "  LATERAL VIEW EXPLODE(subjects) AS subject\n",
    "WHERE EXTRACT(YEAR FROM DATE(projects.endDate)) > 2024\n",
    "GROUP BY subject\n",
    "ORDER BY n_projects DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count projects by subject, aggregate total funded amount\n",
    "\n",
    "Hint: Funded amounts can have different currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT subject,\n",
    "        COUNT(id) AS n_projects,\n",
    "        SUM(granted.fundedAmount) AS funded_total\n",
    "FROM projects\n",
    "    LATERAL VIEW EXPLODE(subjects) AS subject\n",
    "WHERE granted.currency = 'EUR'\n",
    "GROUP BY subject\n",
    "ORDER BY n_projects DESC, funded_total DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count different OA statuses of publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT bestAccessRight.label AS OA_status, COUNT(*) AS n_papers\n",
    "FROM publications\n",
    "GROUP BY bestAccessRight.label\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count OA statuses of all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT bestAccessRight.label AS accessright,\n",
    "       SUBSTRING(publicationDate, 0,4) AS year,\n",
    "       COUNT(*) AS count\n",
    "FROM (SELECT id, bestAccessRight, publicationDate FROM publications \n",
    "        UNION \n",
    "      SELECT id, bestAccessRight, publicationDate FROM datasets\n",
    "        UNION\n",
    "      SELECT id, bestAccessRight, publicationDate FROM software\n",
    "        UNION\n",
    "      SELECT id, bestAccessRight, publicationDate FROM others) as products\n",
    "WHERE bestAccessRight IS NOT NULL AND bestAccessRight IS NOT NULL\n",
    "GROUP BY bestAccessRight, year\n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** explore instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT instance.type as instance_type, COUNT(*) AS count\n",
    "FROM publications\n",
    "    LATERAL VIEW EXPLODE(instances) AS instance\n",
    "GROUP BY instance_type\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** restrict to specific instance types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(DISTINCT id)\n",
    "FROM publications\n",
    "  LATERAL VIEW EXPLODE(instances) AS instance\n",
    "WHERE instance.type IN ('Article',\n",
    "                       'Book',\n",
    "                       'Conference object',\n",
    "                       'Part of book or chapter of book',\n",
    "                       'Data Paper',\n",
    "                       'Software Paper')\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count peer-reviewed publications per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT country.code AS country, COUNT(DISTINCT id) AS n_pubs\n",
    "FROM publications\n",
    "  LATERAL VIEW EXPLODE(countries) AS country\n",
    "WHERE id IN (SELECT DISTINCT id\n",
    "              FROM publications\n",
    "                LATERAL VIEW EXPLODE(instances) AS instance\n",
    "              WHERE instance.refereed = 'peerReviewed')\n",
    "GROUP BY country\n",
    "ORDER BY n_pubs DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show information about publishing venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT container.issnLinking, container.issnOnline, container.issnPrinted, container.name \n",
    "FROM publications \n",
    "WHERE container IS NOT NULL\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** group and count relations based on their semantics and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT reltype.name, COUNT(*) AS count \n",
    "FROM relations \n",
    "GROUP BY reltype.name \n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** count and sort publications by citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT publications.id, pids.value, COUNT(*) AS count\n",
    "FROM publications \n",
    "    JOIN relations ON publications.id = relations.target\n",
    "WHERE reltype.name = 'Cites'\n",
    "GROUP BY publications.id, pids.value\n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the journals with the highest number of publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT container.name, COUNT(id) as n_pubs\n",
    "FROM publications\n",
    "WHERE container IS NOT NULL\n",
    "GROUP BY container.name\n",
    "ORDER BY n_pubs DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the number of projects per organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: the `COALESCE` function can be oh help to select over the possible name forms of an organisation (e.g., short and full name). You can specify multiple columns to select and it will return the first column that is not null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COALESCE(legalshortname, legalname) AS name, \n",
    "        COUNT(*) AS count \n",
    "FROM organizations \n",
    "    JOIN relations ON organizations.id = relations.source\n",
    "                    AND reltype.name = 'isParticipant'\n",
    "GROUP BY name \n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show projects with the highest number of associated results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: An `unidentified` project title is a placeholder for all the associations to a funder without knowing the specific project. It should be removed from the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT fundings.shortName, code, title, COUNT(*) AS count \n",
    "FROM projects \n",
    "    JOIN relations ON projects.id = relations.source\n",
    "                    AND reltype.name = 'produces' \n",
    "                    AND not projects.title ilike '%unidentified%' \n",
    "GROUP BY fundings.shortName, code, title\n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings can be manipulated as well on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT CONCAT_WS(' / ',\n",
    "                IF(SIZE(fundings.shortName) > 0, ARRAY_JOIN(fundings.shortName, ',', '-'), '?'), \n",
    "                COALESCE(code, '?'), \n",
    "                SUBSTRING(title, 0, 50)) AS project, COUNT(*) AS count \n",
    "FROM projects \n",
    "    JOIN relations ON projects.id = relations.source \n",
    "                    AND reltype.name = 'produces' \n",
    "                    AND NOT projects.title ilike '%unidentified%' \n",
    "GROUP BY project \n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Task:** show the most co-occurring publication subjects from controlled vocabularies (i.e., scheme != 'keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH subjects AS (\n",
    "    WITH exploded_subjects (\n",
    "        SELECT id, EXPLODE(subjects.subject) AS subject \n",
    "        FROM publications) \n",
    "    SELECT id, subject.value AS `subject` \n",
    "    FROM exploded_subjects \n",
    "    WHERE subject.scheme != 'keyword'\n",
    ")\n",
    "SELECT l.subject AS left, \n",
    "       r.subject AS right, \n",
    "       COUNT(*) AS count\n",
    "FROM subjects AS l \n",
    "    JOIN subjects AS r ON l.id = r.id \n",
    "                        AND l.subject < r.subject\n",
    "GROUP BY left, right\n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the number of research products per organization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation used is the affiliation of an individual to an organisation (i.e., `isAuthorInstitutionOf`), since in our data this relation links products to organization and not authors to organizations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization short names can be empty, so the legal name could be a fallback option to use in `COALESCE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT legalShortName, legalName\n",
    "FROM organizations \n",
    "WHERE legalShortName IS NULL \n",
    "    AND legalName IS NOT NULL\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COALESCE(legalShortName, legalName) AS organization,\n",
    "        COUNT(*) AS count \n",
    "FROM organizations \n",
    "    JOIN relations ON organizations.id = relations.source\n",
    "                    AND relType.name = 'isAuthorInstitutionOf' \n",
    "GROUP BY organization\n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the number of ALL research products (per type) per organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COALESCE(legalShortName, legalName) AS organization, \n",
    "       COUNT(*) AS total,\n",
    "       COUNT(IF(type = 'publication', 1, NULL)) AS publication,\n",
    "       COUNT(IF(type = 'dataset', 1, NULL)) AS dataset,\n",
    "       COUNT(IF(type = 'software', 1, NULL)) AS software,\n",
    "       COUNT(IF(type = 'other', 1, NULL)) AS other\n",
    "FROM (SELECT id, type FROM publications \n",
    "        UNION \n",
    "      SELECT id, type FROM datasets\n",
    "        UNION\n",
    "      SELECT id, type FROM software\n",
    "        UNION\n",
    "      SELECT id, type FROM others) as products \n",
    "    JOIN organizations \n",
    "    JOIN relations ON organizations.id = relations.source\n",
    "                    AND products.id = relations.target \n",
    "                    AND relType.name = 'isAuthorInstitutionOf' \n",
    "GROUP BY organization \n",
    "ORDER BY total DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show publications access types per organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COALESCE(legalShortName, legalName) AS organization, \n",
    "       COUNT(*) as total,\n",
    "       COUNT(IF(bestAccessRight.label = 'OPEN', 1, NULL)) AS open,\n",
    "       COUNT(IF(bestAccessRight.label = 'EMBARGO', 1, NULL)) AS embargo,\n",
    "       COUNT(IF(bestAccessRight.label = 'CLOSED', 1, NULL)) AS closed\n",
    "FROM organizations \n",
    "    JOIN relations \n",
    "    JOIN publications ON organizations.id = relations.source \n",
    "                        AND publications.id = relations.target \n",
    "                        AND relType.name = 'isAuthorInstitutionOf'\n",
    "GROUP BY organization\n",
    "ORDER BY total DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the result access types per country of the organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT organizations.country.code AS country, \n",
    "       COUNT(*) AS total,\n",
    "       COUNT(IF(bestAccessRight.label = 'OPEN', 1, NULL)) AS open,\n",
    "       COUNT(IF(bestAccessRight.label = 'EMBARGO', 1, NULL)) AS embargo,\n",
    "       COUNT(IF(bestAccessRight.label = 'CLOSED', 1, NULL)) AS closed\n",
    "FROM (SELECT id, bestAccessRight FROM publications \n",
    "        UNION \n",
    "      SELECT id, bestAccessRight FROM datasets\n",
    "        UNION\n",
    "      SELECT id, bestAccessRight FROM software\n",
    "        UNION\n",
    "      SELECT id, bestAccessRight FROM others) as products \n",
    "    JOIN organizations \n",
    "    JOIN relations ON organizations.id = relations.source\n",
    "                    AND products.id = relations.target \n",
    "                    AND relType.name = 'isAuthorInstitutionOf'\n",
    "WHERE organizations.country IS NOT NULL\n",
    "GROUP BY organizations.country.code\n",
    "ORDER BY total DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show international project collaborations; focus on organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH countryProject AS (\n",
    "    SELECT country.code AS country, \n",
    "           target AS id \n",
    "    FROM organizations \n",
    "        JOIN relations ON reltype.name = 'isParticipant' \n",
    "                        AND source = organizations.id\n",
    "    WHERE country IS NOT NULL\n",
    ")\n",
    "SELECT l.country AS left, \n",
    "       r.country AS right, \n",
    "       COUNT(*) AS count \n",
    "FROM countryProject AS l \n",
    "    JOIN countryProject AS r ON l.id = r.id \n",
    "                                AND l.country < r.country\n",
    "GROUP BY left, right \n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the organisations collaborating in projects more often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH orgProject AS (\n",
    "    SELECT COALESCE(legalshortname, legalname) AS organization, \n",
    "           target AS id \n",
    "    FROM organizations \n",
    "    JOIN relations ON reltype.name = 'isParticipant' \n",
    "                    AND source = organizations.id\n",
    ")\n",
    "SELECT l.organization AS left,\n",
    "       r.organization AS right,\n",
    "       COUNT(*) AS count\n",
    "FROM orgProject AS l \n",
    "    JOIN orgProject AS r ON l.id = r.id \n",
    "                            AND l.organization < r.organization\n",
    "GROUP BY left, right \n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the organizations co-authoring papers more often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH orgProduct AS (\n",
    "    SELECT COALESCE(legalshortname, legalname) AS organization, \n",
    "           target AS id \n",
    "    FROM organizations \n",
    "        JOIN relations ON reltype.name = 'isAuthorInstitutionOf' \n",
    "                        AND source = organizations.id\n",
    ")\n",
    "SELECT l.organization AS left, \n",
    "       r.organization AS right,\n",
    "       COUNT(*) AS count \n",
    "FROM orgProduct AS l \n",
    "    JOIN orgProduct AS r ON l.id = r.id \n",
    "                        AND l.organization < r.organization\n",
    "GROUP BY left, right \n",
    "ORDER BY count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the number of publications supplemented by datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*) AS count\n",
    "FROM relations \n",
    "    JOIN publications \n",
    "    JOIN datasets ON reltype.name = 'IsSupplementedBy' \n",
    "                    AND publications.id = relations.source \n",
    "                    AND datasets.id = relations.target\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the number of peer reviewed publications with doi split by openAccessColor and the availability of a green deposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT COUNT(id), isGreen , openAccessColor\n",
    "FROM publications\n",
    "WHERE ARRAY_CONTAINS(instances.refereed, 'peerReviewed') \n",
    "    AND  ARRAY_CONTAINS(pids.scheme, 'doi')\n",
    "    AND isGreen IS NOT NULL \n",
    "    AND openAccessColor IS NOT NULL\n",
    "GROUP BY openAccessColor, isGreen\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing data to other libaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** show the collaboration network of countries participating in projects with respect to the partecipating organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH countryProject AS (\n",
    "    SELECT country.code AS country, \n",
    "           target AS id \n",
    "    FROM organizations JOIN relations ON reltype.name = 'isParticipant' AND source = organizations.id\n",
    "    WHERE country IS NOT NULL\n",
    ")\n",
    "SELECT l.country AS left, \n",
    "       r.country AS right,\n",
    "       COUNT(*) AS count \n",
    "FROM countryProject AS l \n",
    "    JOIN countryProject AS r ON l.id = r.id \n",
    "                                AND l.country <= r.country\n",
    "GROUP BY left, right \n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "edges = spark.sql(query).toPandas()\n",
    "edges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be modeled as a graph and analysed. Let's try doing so with igraph and feed it with country couples and the number of coparticipated projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "G = ig.Graph.TupleList(\n",
    "    edges=edges[['left', 'right', 'count']].values,\n",
    "    vertex_name_attr='countrycode',\n",
    "    edge_attrs = ['weight'],\n",
    "    directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the number of nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.vcount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.ecount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generic node can be inspected like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.vs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, a generic edge can be inspected with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.es[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Let's try to plot something. The whole network looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "max_w = np.max(G.es['weight'])\n",
    "ig.plot(G, vertex_label=G.vs['countrycode'], vertex_size=10, edge_width=2, edge_color='gray', target=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's filter by country, say Italy (i.e., IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = G.induced_subgraph(G.neighborhood(G.vs.find(countrycode_eq = 'IT')))\n",
    "H.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.vs['color'] = 'blue'\n",
    "H.vs.find(countrycode_eq = 'IT')['color'] = 'red'\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ig.plot(H, vertex_label=H.vs['countrycode'], vertex_size=30, edge_width=2, edge_color='gray',target=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a lot of collaborations there. Let's plot a country with less collaborations, say Maldives (i.e., MV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = G.induced_subgraph(G.neighborhood(G.vs.find(countrycode_eq = 'MV'))) # Maldives\n",
    "H.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "H.vs['color'] = 'blue'\n",
    "H.vs.find(countrycode_eq = 'MV')['color'] = 'red'\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ig.plot(H, vertex_label=H.vs['countrycode'], vertex_size=30, edge_width=2, edge_color='gray',target=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "name": "openaire_beginners_kit SQL"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
